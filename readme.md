## 该仓库的本分支主要目的
该分支主要是为了讲解一些关于如何使用 python 来实现爬取网页的方法的仓库分支

* 第一步: 了解 python requests module 的使用
  * 普通的 `get` 请求如何实现
  * 普通的 `post` 请求如何实现
  * 携带请求参数的 `get` 请求
  * 携带请求参数的 `post` 请求
  * 如何获取不同格式的响应数据: `text content json status_code`
  * 设置请求头伪装自己的方法: `headers`
  * 前后端交互重要知识点: 会话维持 `session` `cookie`


* 第二步: 了解 python jsonpath module 的使用
  * 理解前端的异步加载和同步加载
  * 了解开发一个项目的总的开发流程
  * 使用新的处理数组方法
  * 爬取网页的时候的递归以及异常捕获的处理
  * 拓展使用 openpyxl 实现操作 excel 表


* 第三步： learn bs4
  * 知道如何通过标签选择器获取我们的数据
  * 了解 `find_all` 的使用
  * 了解 `.selet()` 的使用


* 第四步： learn xpath
  * 首先我们实现使用这个模块的时候
  * 我们首先需要做的就是我们的进行
  * 学习其中的语法即可
  * 然后这个的使用就是直接从我们的 lxml 解析器中实现获取


* 推荐使用 fiddler 工具
  * fiddler 就是位于我们的客户端和服务端之间的一种代理
    * 也是当前最常见的抓包工具
  * 该工具可以实现我们的记录客户端和服务端之间的所有的请求
    * 可以实现针对特定的请求实现分析数据，请求数据，设置断点，调试web应用
      * 修改请求的数据，甚至是实现修改服务器返回的数据，是我们的 web 调试的利器

![image01](/images/image01.png)
* 没有使用 fiddler 的时候，
  * 直接是 客户端给服务端发送请求，然后服务端给客户端响应
* 使用了 fiddler 之后
  * 客户端先把请求发给 fiddler,然后把请求发送给服务端
  * 服务端实现响应数据也是先把响应给 fiddler,然后给客户端
  * 想用就用，不用就不用，没强制要求（个人感觉不好用）